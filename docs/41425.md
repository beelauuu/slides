---
marp: true
theme: default
class: invert
style: |
    section {
        font-size: 180%;
    }
    footer {
        font-size: .6em;
    }
paginate: true
---
<!-- 
_paginate: false
_class: invert
-->

# <!--fit--> Discussion 18
<!-- 
_footer: "Credits to Adit Bala for the MARP template <3"
-->

### "Lambda expressions are like good secrets—once you pass them around, they never get named!"

Brian Lau

`blau1@umd.edu`

---
## Agenda
<!-- 
_footer: Slides available at [`teaching.beelau.dev`](https://teaching.beelau.dev)
-->
1. QuickSort Lecture
3. Office Hours / Lecture Review
---

## Announcements :mega:
<!-- 
_footer: Slides available at [`teaching.beelau.dev`](https://teaching.beelau.dev)
-->
- `Project 6`
    - Due: `Tomorrow @ 11:30 PM`
    - Note: It will be `11:30 PM` not `11:59 PM`
---
# QuickSort
- Let's go over the concepts of QuickSort
- Import in the `NLogNSort.zip` file from the class website as well!
---
# Introduction to Quick Sort

- Quick Sort is a divide-and-conquer sorting algorithm.
- It was developed by Tony Hoare in 1959.
- It works by:
  - Choosing a pivot
  - Partitioning the array into two sub-arrays:
    - Elements less than the pivot
    - Elements greater than the pivot
  - Recursively sorting the sub-arrays

---

# Why Use Quick Sort?

- Fast in practice: Average time complexity is $O(n \log n)$
- In-place sorting: Requires only $O(\log n)$ space on average for recursion
- Commonly used in real-world applications (e.g., Java's built-in sort for primitives)

| Algorithm | Time (Average) | Time (Worst) | Space |
|-----------|----------------|--------------|-------|
| Quick Sort | $O(n \log n)$ | $O(n^2)$ | $O(\log n)$ |
| Merge Sort | $O(n \log n)$ | $O(n \log n)$ | $O(n)$ |
| Insertion Sort | $O(n^2)$ | $O(n^2)$ | $O(1)$ |

---

# The High-Level Algorithm

```
quickSort(arr, low, high):
    if low < high:
        pivotIndex = partition(arr, low, high)
        quickSort(arr, low, pivotIndex - 1)
        quickSort(arr, pivotIndex + 1, high)
```

- Sorts elements between low and high
- Partition puts the pivot in its correct place
- Recursively sort left and right sub-arrays

- **Partitioning (Hard Split)**: The work-intensive part of Quick Sort is the partitioning step, where elements are rearranged around a pivot.
- **Recursion (Easy Merge)**: After partitioning, the sub-arrays are recursively sorted. No merging is required; the array elements are "sorted in place" as the recursion works.

---

# Partitioning Explained

- Choose a pivot (e.g., last element)
- Use two pointers:
  - i tracks position for smaller elements
  - j iterates from low to high - 1
- Swap arr[i] and arr[j] when arr[j] < pivot
- Finally, place the pivot at i + 1

- **After Partitioning**: Once the partitioning step is complete, the pivot will be in its correct and final position. This means that the pivot element will never move again.
- **Smaller Elements on the Left**: All elements smaller than the pivot will be placed in the left half of the array.
- **Larger Elements on the Right**: All elements larger than the pivot will be placed in the right half of the array.

---

# Partitioning Explained (continued)

- **What Happens Next**: After the partitioning, the array is divided into two sub-arrays (left and right of the pivot). Each sub-array is then treated as a new input to the same algorithm.
- **Recursion's Power**: The same Quick Sort algorithm is applied to these sub-arrays, which are now smaller and simpler. The process repeats until the sub-arrays become so small (typically a single element) that they are trivially sorted.

---

# Step-by-Step Example

Input: `arr = [10, 3, 7, 2, 6]` (Pivot = 6, the last element)

- Start with i = -1 (index of last element smaller than the pivot)

1. i = -1, j = 0 (element = 10):
   - 10 > 6, do nothing. i stays at -1.

2. i = -1, j = 1 (element = 3):
   - 3 < 6, increment i to 0, swap arr[0] and arr[1].
   - New array: [3, 10, 7, 2, 6]

3. i = 0, j = 2 (element = 7):
   - 7 > 6, do nothing. i stays at 0.

---

# Step-by-Step Example (continued)

4. i = 0, j = 3 (element = 2):
   - 2 < 6, increment i to 1, swap arr[1] and arr[3].
   - New array: [3, 2, 7, 10, 6]

5. i = 1, j = 4 (pivot = 6):
   - Place pivot in correct position by swapping arr[i+1] and pivot.
   - Swap arr[2] and arr[4].
   - Final array: [3, 2, 6, 10, 7]

**Key Points**:
- Pivot (6) is now in its correct position
- Left sub-array contains elements smaller than pivot
- Right sub-array contains elements larger than pivot
- Process repeats recursively with smaller sub-arrays

---

# Time Complexity

| Case | Time Complexity |
|------|-----------------|
| Best Case | $O(n \log n)$ |
| Average Case | $O(n \log n)$ |
| Worst Case | $O(n^2)$ |

- **Worst case** happens when:
  - Pivot is always the smallest or largest element
  - Example: Already sorted input with naive pivot choice

- **Ways to improve**:
  - Randomized Pivot: Pick a random element as pivot
  - Median-of-Three Pivot: Use the median of first, middle, and last
  - Switch to Insertion Sort for small sub-arrays (e.g., size < 10)

---

# Proving Quick Sort is $O(n \log n)$ for 50-50 Split

Let's assume that at each recursion step, the array is split into two roughly equal halves:

1. **Initial Array** (n elements):
   - Total work at first level: n (all elements compared to pivot)

2. **Second Level of Recursion**:
   - Two sub-arrays each contain n/2 elements
   - Total work: n/2 + n/2 = n

3. **Third Level of Recursion**:
   - Four sub-arrays each containing n/4 elements
   - Total work: n/4 + n/4 + n/4 + n/4 = n

---

# Proving Quick Sort is $O(n \log n)$ for 50-50 Split (continued)

- At each level of recursion:
  - We split the array into two
  - Total work done at each level is $O(n)$
  - Number of levels is $\log_2 n$ (array size keeps halving)

- Total work done is the sum of all levels:
  - Work per level: $O(n)$
  - Number of levels: $O(\log n)$
  - Overall time complexity: $O(n) \times O(\log n) = O(n \log n)$

**Note #1**: Quick Sort maintains $O(n \log n)$ for non-perfect but relatively balanced splits (e.g., 60-40, 70-30).

**Note #2**: QuickSort is in $\Omega(n \log n)$ - this is the least amount of work any comparison-based sorting algorithm can possibly do.

---

# Space Complexity of Quick Sort

- **In-place sorting**:
  - QuickSort doesn't use extra arrays — all swaps happen inside the original array

- **What about recursion?**
  - Each recursive call adds a frame to the call stack

- **Best and Average Case**:
  - If each pivot splits the array roughly in half:
  - Recursion depth is $\log_2 n$
  - Call stack only grows to $O(\log n)$

- **Worst Case**:
  - If pivot always picks smallest/largest value (bad splits):
  - Recursion depth becomes $n$
  - Space usage becomes $O(n)$

---
# Thank you! Any questions?

### Remember to give feedback if you have any!